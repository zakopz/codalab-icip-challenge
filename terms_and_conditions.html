<h3>Terms and Conditions</h3>
<p><span>The LVQ dataset would be made available to the participants once the challenge opens. The participants would be required to use this database to develop a single classification algorithm that is able to classify distortions in all the videos in real-time. The participants would be required to submit an easily readable code of their algorithm (preferably in Matlab or Python) with comments along with a document describing a brief summary and steps of their method. Moreover, each solution should also contain a demo code which could be used to run the submitted solution using a test video. The classification results should also be displayed in real-time on the tested video (or on a console window/terminal alongside) while the video is being played. In case of multiple distortions, all classes should be displayed. The participants must also share the speed of their code and the system specifications on which it was run.</span></p>